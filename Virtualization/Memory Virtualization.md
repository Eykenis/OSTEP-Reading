# 虚拟化内存

现代操作系统虚拟化内存主要的工作是将物理内存地址成逻辑内存，来简化用户对内存的管理（有时候几乎不需要用户进行管理），并创造一种内存很多，而且程序使用的内存好像都是自己私有的假象，让程序打消对 “还有多少空间可用”，怎么使用的顾虑。

> 私以为，虚拟化内存其实就是一种 “映射的艺术”，做的就是如何把物理内存**映射**到逻辑内存，来让内存的使用变得优雅。

## 概念：地址空间

地址空间是对内存地址的一种抽象，是**运行的程序看到的系统中的内存**。

例如，在用 C 编译程序的时候，你的程序能访问到的一系列**连续的**逻辑地址，就是分配给你的一批内存空间，称为地址空间。它的结构通常由程序代码、堆和栈组成。当然，堆和栈之间会有一些分配但未使用的空间，用于接受堆和栈的增长。通常，栈的起始点在最大地址处，**栈是向下增长的**；而最小地址处首先是程序的代码和固定数据，紧接着是**向上增长的堆**。

然而虽然显示给用户的逻辑地址是连续的，但其在物理内存中通常不会是连续的，甚至顺序也会有区别。这是我们的虚拟化技术造成的结果。

## 机制：地址转换

当程序需要使用内存时，硬件对内存访问进行处理，将程序访问的虚拟地址转换为实际的物理地址。这个过程就叫做地址转换。而如何进行转换，还需要靠操作系统的介入，需要记录当前内存中哪些地址被占用了，哪些是空闲的，等等问题。

### 基址加界限机制

一种最基础的硬件地址转换方法。我们会使用一个**基址寄存器**和一个**界限寄存器**。当操作系统决定好物理内存从哪里开始时，这个起始地址就会被加载到基址寄存器，并把内存大小加载到界限寄存器中。当访问的内存超出基址+界限的范围时，就会被视为非法的内存访问。

例如，逻辑地址 0 被映射到物理内存 0x128，界限为 32bit. 那么逻辑地址的范围就是 0 \~ 31，映射到的物理地址就是 0x128 \~ 0x147.

基址加界限机制的内存分配是在运行时发生的，并且可以被改变（只需要改变寄存器即可），所以也称为动态重定位。

那么，这个机制需要哪些配套的硬件机制？

- 特权模式和用户模式，防止用户进行特权操作
- 基址/界限寄存器
- 地址转换算法和相应电路，以及检查是否越界的机制
- 修改基址/界限寄存器的指令
- 注册异常处理程序的指令，用于指定异常处理程序的代码
- 正确产生异常的机制。通常需要 CPU 中断进程，并执行相应异常处理

### 还需要哪些支持

在拥有基址加界限机制后，我们就有了一些新问题：

- 怎么去决定地址转换的算法？
- 进程终止时，操作系统如何回收内存？
- 上下文切换时，如何保存内容？
- 异常处理程序如何工作？

## 地址转换机制

解决如何进行地址转换的问题。

### 分段

简单来说，分段机制将内存分成了一个个段。当你需要使用内存时，系统就会分一个段供你使用。分段机制让一个程序使用的内存在物理上不连续成为了可能。例如，从分段机制开始，之前讨论的地址空间被我们 “拆开” 了。现在，硬件不再为堆和栈预留空间，而是等到用的时候才给他们分配。

怎么进行地址转换？现在，我们会有一个**段寄存器**。它的值由两部分组成。高的若干位为**段号**，而低位为**偏移量**。

例如，规定 14 位段寄存器的高 2 位为段号，低 12 位为偏移量，现在有一个地址值为 01000001101000，其段号就是 01，我们找到第 01 个段的起始地址，然后往后再移动 000001101000 次，就找到了实际的物理地址。

那么，现在程序需要一些空间的时候，系统就会在内存中找到一个空闲段，然后把地址存到段寄存器中，并分配给程序。

#### 栈的反向增长问题

上述的偏移量默认为正向增长。但程序的栈通常都规定是反向增长的。所以还需要增加一位用于标识增长方向。

#### 共享的保护问题

为了节省内存，有时候系统会适当地共享内存。但是有的内存是不能共享的。所以还需要添加一个标记，用于标识该处可否读，可否写，可否执行等信息。当然，这些共享是不会被用户发现的。

#### 碎片问题

为了操作的简单，我们会规定初始时所有的段大小相同。那么在分配时难免出现碎片问题，就好比除法会有除不尽的问题。比如我们需要 3KB 的内存，而段大小是 4KB，我们找到了一个合适段，然后分出来 3KB 空间，而剩下的 1KB 就自成一个新段。长此以往，内存中就会有很多很多大小很小的段，这就会导致一个问题：找不到合适大小的段。比如所有的段都被碎片化为 1KB 了，现在我再需要一个 3KB 的空间，我就会找不到一个合适的段，唯一的机会就是等其他程序使用完它们的内存并释放后去获得空间。

上面说的这种碎片问题叫做**外部碎片**，即没有被分配的空闲空间很小，导致其难以满足接下来的分配请求，形成了碎片。

还有一种碎片问题叫**内部碎片**，即某个内存被分配给了一个程序，但是这个程序对其分配到的一部分内存几乎不使用，也就是俗称 “分多了”，多分的这块空间没有被使用，但却被分配出去了，也就让其他程序无法使用这块实际上空闲的空间。

### 空闲空间管理

#### 空闲列表

空闲列表让内存的管理变得很方便。我们将所有空闲的内存串成一个链表，当分配时，就从链表中遍历，找到符合要求的内存段，然后把这段分配出去，并从链表中删除属于这段内存的节点。而当释放内存时，我们又找到其原本在列表中的位置，并把其插入回去。

除了管理分配与释放的功能以外，空闲列表还支持碎片空间合并。在释放内存时，把归还的空间和与其相邻的内存段合并为一个段，这样能有效地缓解碎片问题（但不能完全消除）。

#### 内存分配策略

为了缓解碎片问题，我们还可以在内存分配上下手。决定将哪一块分配给程序也是十分重要的。

- **最优匹配**

	遍历整个列表，找到所有符合要求的内存块中**最小的**。其思想是避免空间的浪费。

- **最差匹配**

	遍历整个列表，找到所有符合要求的内存块中**最大的**。其思想是尽可能地让内存碎片更大，减小碎片的影响。**不过其效果非常差。**虽然想的好，但实际应用中通常会产生非常多的碎片，并且开销也和最优匹配一样大。

- **首次匹配**

	从空闲列表中找到第一个足够大的块就直接返回。好处是一般情况下不需要遍历所有节点，速度快。

- **下次匹配**

	多维护一个指针，每次不从列表起始处开始遍历，而是从上次分配空间的下一个节点但开始找。这样可以避免首次匹配中频繁对列表开头进行分割的问题。

### 分页

和分段相比，分页将致力于解决内存碎片，并同时尽可能减少空间和时间开销。

和分段相似，分页机制的虚拟地址也由两部分构成：页号和偏移量。这里的页是虚拟的。首先，我们会在内存中保存一个页表，这个页表就是一个逻辑页号到物理页号的映射。而且**每个进程都有自己独特的一个页表**。访问时，先找到页表，然后访问对应逻辑页号对应的物理页号，找到物理页的起始位置后，再加上偏移量，完成地址访问。

每个页表项除了存储物理页号的位置，还会存储一些其他的信息。包括该页是否有效的有效位、表明页是否可以读写执行的保护位，页在内存上还是在磁盘/SSD 上的存在位和参考位。

还有一点和分段不同的就是，页表项相对段项更多，每个页的大小通常很小，而且内存分配时会为需要的请求分配多个页面，直到大小足够。这与段机制找到一个足够大的段的策略是不同的。

#### 快速地址转换 TLB

TLB 实际上是一种缓存，用于存放最近访问过的页表项。当我们要找一个页的时候，本来需要先访问内存中的页表，然后再跳转到相应物理页。但当 TLB 存了最近访问过的页的位置后，我们就可以直接从高速缓存中查找，有没有我们所需要的页索引，如果有，就可以通过 TLB 直接跳转，避免了更慢的内存访问。

有 TLB 支持时，内存访问工作的基本流程：

读取逻辑页号 ---> 从 TLB 中查找 ---> 找到转换映射（TLB hit）---> 访问相应物理页位置

OR：
读取逻辑页号 ---> 从 TLB 中查找 ---> 未找到转换映射（TLB miss）---> 从内存中找页表项 ---> 更新 TLB ---> 再次从 TLB 中查找 ---> TLB hit ---> 访问相应物理页位置

##### 有 TLB 时的上下文切换

TLB 只对一个进程有意义。这是因为每个进程都有自己的页表。切换进程时，原来的页表就没有用了。

解决办法有两种，一是简单地清空 TLB，但是有相当的开销；还有一种办法是为 TLB 项添加一个 ASID 标识符，类似于 PID，用于标识其属于哪个进程。

>### 一个小问题：为什么每个进程都需要自己的页表？
>
>如果所有进程共用一个页表，那不就没有 TLB 切换了吗？而且共用一个页表可以极大地减少内存开销。毕竟每个进程都存一个页表，加起来也是有相当空间的。
>
>**一天后自己的回答**：怎么会这样呢（笑），每个进程之间访问的物理空间必须是相互独立的，这样才能保证进程之间被隔离，不相互影响。所以页表指向的地址当然不同。
>
>下面是一些其他相关概念：
>
>#### 内核空间与用户空间
>
>通常，地址空间被划分为内核地址空间和用户地址空间。内核地址空间占虚拟地址空间的高位部分，用户地址空间占虚拟地址的低位部分。进程运行在其地址空间的内核空间时，就称其为在内核态，否则称为用户态。
>
>用户态和内核态下使用不同的页表。规定用户态的页表是每个进程独有的，而内核态的页表是共享的。但是实际使用中，每个进程还是会将页表的内核空间部分拷贝到自己的页表中。这样做是为了在内核态和用户态间切换时不需要切换页表，从而节省时间。
>
>**为什么需要共享内核页表？**主要还是考虑性能，避免内核到用户切换时的性能问题。因为共享的时候，我们将内核页表深拷贝到进程页表中将更方便。
>
>**为什么需要将内核部分拷贝到进程自己的页表内？**[[ARM Linux\] 每个进程的内核页表为什么单独分配存储空间？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/26825537)
>
>#### 页表在哪里
>
>为了防止用户对页表进行修改，页表一定是要存在内核空间中的。但是访问页表时不需要进行内核态切换，因为获取页表项的工作是交给硬件完成的。

#### 多级页表

多级页表解决的问题主要是去掉线性页表中的无效项（例如两个页之间可能有很多页都是无效的，但读取的时候仍然需要将它们一起加载到内存中）。只需要使用一个二级页表，我们就可以通过高级页表的表项决定要访问哪一个页。而高级页表比低级页表小得多，因为它是 “页表的页表”。由此，我们可以大大减少页表在内存中占用的空间。

但是二级页表也有其时间成本。当 TLB 未命中时，我们需要从内存中加载两次才能得到地址。未命中的时间代价增加了。

> #### 为什么不讨论和多级页表目的相似的段页式存储结构
>
> 现代 x86_64 架构早就抛弃段页式了。因为寻址空间越来越大，x64 采用四级页表，页大小为 4KB，线性地址分级为 9+9+9+9+12. 已经过时被抛弃的段页式这里就不说啦
>
> 清华大学的 os_kernel_lab 模拟的是 80386 架构，仍然使用段页式，实验指导书中有较为详细的讲解。

## 超越物理内存：使用外存来模拟

当内存中没有办法放入所有需要的地址空间时，一种简单的想法是将地址空间存到外部存储中，需要时再将其加载到内存里来。

所以，我们会在外存中开辟一部分空间专门用于管理物理页的移入和移出，这部分称为**交换空间**。

## 支持交换空间的机制

### 存在位

就像 TLB 一样，我们需要知道现在访问的页是否在内存中。如果不是，还要从外存中加载。但和 TLB 不同的是，我们万万不能像从 TLB 中直接找那样去从内存中找（失败了再去外存中找），那样的开销太大了。

所以，我们需要在页表项 PTE 中再添加一点信息。**使用一个存在位来标识该页是否在内存中。**

### 页错误 page fault

当页面不在内存中时，就会产生页错误。那么，当知道页在外存中时，怎么知道在外存的哪里呢？答案是给页表项再添加一些存储在外存中位置的位。

因为访问外存是 I/O 操作，会消耗大量时间。所以自然而然地，发生页错误的进程将进行 I/O，并进入阻塞状态，从而保持 CPU 的高速运行。

### When memory is full

当内存已经满了，不允许我们再添加新的页进来了，我们就需要将已经有的页拿走，放回外存。这就是**页交换**。

> **高水位线机制**
>
> 为了防止频繁的页交换，操作系统会想办法在某个时刻留一些内存空间。高水位线机制就是一种预留内存的方法。
>
> 操作系统会设置一个高水位线 HW 和一个低水位线 LW。当系统剩余的空间可存放的页数少于 LW 时，**交换守护进程**就会启动，不断地将页放回外存，直到剩余空间可存放 HW 个页。

那么该拿走哪个页呢？

### 页替换策略

#### 最优策略

#### FIFO

#### 随机化

#### LRU

#### 近似 LRU

### 抖动问题



